# @package _global_
defaults:
  - override /policy: act
  - override /env: pusht


dataset_repo_id: lerobot/pusht

override_dataset_stats:
  # TODO(rcadene, alexander-soare): should we remove image stats as well? do we use a pretrained vision model?
  observation.image:
    mean: [[[0.5]], [[0.5]], [[0.5]]]  # (c,1,1)
    std: [[[0.5]], [[0.5]], [[0.5]]]  # (c,1,1)
  # TODO(rcadene, alexander-soare): we override state and action stats to use the same as the pretrained model
  # from the original codebase, but we should remove these and train our own pretrained model
  observation.state:
    min: [13.456424, 32.938293]
    max: [496.14618, 510.9579]
  action:
    min: [12.0, 25.0]
    max: [511.0, 511.0]

wandb:
  enable: true
  disable_artifact: true




policy:

  chunk_size: 20
  n_action_steps: 10


  input_shapes:
    # TODO(rcadene, alexander-soare): add variables for height and width from the dataset/env?
    observation.image: [3, 96, 96]
    observation.state: ["${env.state_dim}"]
  output_shapes:
    action: ["${env.action_dim}"]

  # Normalization / Unnormalization
  input_normalization_modes:
    observation.image: mean_std
    observation.state: min_max
  output_normalization_modes:
    action: min_max

  kl_weight: 20.0


training:
  offline_steps: 200000
  online_steps: 0
  eval_freq: 5000
  save_freq: 50000
  log_freq: 250
  save_checkpoint: true

  batch_size: 64
  lr: 5e-5
  lr_backbone: 5e-5
  weight_decay: 1e-4
  grad_clip_norm: 10
  online_steps_between_rollouts: 1

  delta_timestamps:
    action: "[i / ${fps} for i in range(${policy.chunk_size})]"


hydra:
  job:
    name: pusht-act
