{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\"lerobot/aloha_sim_insertion_human_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'observation.images.top': Image(mode=None, decode=True, id=None),\n",
       " 'observation.state': Sequence(feature=Value(dtype='float32', id=None), length=14, id=None),\n",
       " 'action': Sequence(feature=Value(dtype='float32', id=None), length=14, id=None),\n",
       " 'episode_index': Value(dtype='int64', id=None),\n",
       " 'frame_index': Value(dtype='int64', id=None),\n",
       " 'timestamp': Value(dtype='float32', id=None),\n",
       " 'next.done': Value(dtype='bool', id=None),\n",
       " 'index': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]\n",
    "dataset['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'observation.images.top': Image(mode=None, decode=True, id=None),\n",
       " 'action': Sequence(feature=Value(dtype='float32', id=None), length=14, id=None),\n",
       " 'episode_index': Value(dtype='int64', id=None),\n",
       " 'frame_index': Value(dtype='int64', id=None),\n",
       " 'timestamp': Value(dtype='float32', id=None),\n",
       " 'next.done': Value(dtype='bool', id=None),\n",
       " 'index': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "l = dataset.remove_columns(\"observation.state\")\n",
    "l[\"train\"].features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.features import Value, Sequence, Image, Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GELLO dataset to Lerobot dataset\n",
    "\n",
    "\n",
    "gello\n",
    "\n",
    "/episodes/\n",
    "    episodeX/\n",
    "        pickleY -> dict of numpy arrays.\n",
    "\n",
    "\n",
    "should add following dict keys:\n",
    "- episode_index\n",
    "- frame_index\n",
    "- next.done\n",
    "- timestamp (how? simply assume fixed fps?)\n",
    "- index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://cloud.ilabt.imec.be/index.php/s/2KWj4XJFzkbLbRE/download/planar_push_gello.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip planar_push_gello.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrist_rgb\n",
      "<class 'numpy.ndarray'>\n",
      "(480, 640, 3)\n",
      "wrist_depth\n",
      "<class 'numpy.ndarray'>\n",
      "(480, 640, 1)\n",
      "base_rgb\n",
      "<class 'numpy.ndarray'>\n",
      "(480, 640, 3)\n",
      "base_depth\n",
      "<class 'numpy.ndarray'>\n",
      "(480, 640, 1)\n",
      "joint_positions\n",
      "<class 'numpy.ndarray'>\n",
      "(6,)\n",
      "tcp_pose_quat\n",
      "<class 'list'>\n",
      "gripper_position\n",
      "<class 'numpy.ndarray'>\n",
      "(1,)\n",
      "wrench\n",
      "<class 'list'>\n",
      "control\n",
      "<class 'numpy.ndarray'>\n",
      "(6,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'wrist_rgb': Image(mode=None, decode=True, id=None),\n",
       " 'wrist_depth': Image(mode=None, decode=True, id=None),\n",
       " 'base_rgb': Image(mode=None, decode=True, id=None),\n",
       " 'base_depth': Image(mode=None, decode=True, id=None),\n",
       " 'joint_positions': Sequence(feature=Value(dtype='float64', id=None), length=6, id=None),\n",
       " 'tcp_pose_quat': Sequence(feature=Value(dtype='float64', id=None), length=6, id=None),\n",
       " 'gripper_position': Sequence(feature=Value(dtype='float64', id=None), length=1, id=None),\n",
       " 'wrench': Sequence(feature=Value(dtype='float64', id=None), length=6, id=None),\n",
       " 'control': Sequence(feature=Value(dtype='float64', id=None), length=6, id=None),\n",
       " 'frame_index': Value(dtype='int64', id=None),\n",
       " 'episode_index': Value(dtype='int64', id=None),\n",
       " 'index': Value(dtype='int64', id=None),\n",
       " 'next.done': Value(dtype='int64', id=None),\n",
       " 'next.success': Value(dtype='int64', id=None),\n",
       " 'timestep': Value(dtype='float64', id=None)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pickle \n",
    "import numpy as np \n",
    "from PIL import Image as PILImage\n",
    "\n",
    "data_dir = Path(\"planar_push_gello\")\n",
    "episode_paths = list(data_dir.glob(\"*\"))\n",
    "episode_paths = sorted(episode_paths)\n",
    "episode_paths\n",
    "\n",
    "step_path = list(episode_paths[0].glob(\"*.pkl\"))[0]\n",
    "step_dict = pickle.load(open(step_path, \"rb\"))\n",
    "\n",
    "dataset_keys = list(step_dict.keys())\n",
    "\n",
    "gello_dataset_features = {}\n",
    "for key in dataset_keys:\n",
    "    print(key)\n",
    "    print(type(step_dict.get(key)))\n",
    "    if type(step_dict.get(key)) == np.ndarray:\n",
    "        print(step_dict.get(key).shape)\n",
    "        if len(step_dict.get(key).shape) ==0:\n",
    "            if  type(step_dict.get(key)) == np.float64 or type(step_dict.get(key)) == np.float32:\n",
    "                gello_dataset_features[key] = Value(\"float64\")\n",
    "            elif type(step_dict.get(key)) == np.int64 or type(step_dict.get(key)) == np.int32 or type(step_dict.get(key)) == np.int16:\n",
    "                gello_dataset_features[key] = Value(\"int64\")\n",
    "\n",
    "        elif len(step_dict.get(key).shape) ==1:\n",
    "            if  type(step_dict.get(key)[0]) == np.float64 or type(step_dict.get(key)[0]) == np.float32:\n",
    "                gello_dataset_features[key] = Sequence(Value(\"float64\"),length = len(step_dict.get(key)))\n",
    "            elif type(step_dict.get(key)[0]) == np.int64 or type(step_dict.get(key)[0]) == np.int32 or type(step_dict.get(key)[0]) == np.int16:\n",
    "                gello_dataset_features[key] = Sequence(Value(\"int64\"),length = len(step_dict.get(key)))\n",
    "\n",
    "        elif len(step_dict.get(key).shape) ==3:\n",
    "            gello_dataset_features[key] = Image()\n",
    "        \n",
    "        else:\n",
    "            print(\"could not find type for key\")\n",
    "            print(key, type(step_dict.get(key)))\n",
    "\n",
    "    elif type(step_dict.get(key)) == list:\n",
    "        if  type(step_dict.get(key)[0]) in [ np.float64, np.float32, np.float16, float]:\n",
    "            gello_dataset_features[key] = Sequence(Value(\"float64\"),length = len(step_dict.get(key)))\n",
    "        elif type(step_dict.get(key)[0]) == np.int64 or type(step_dict.get(key)[0]) == np.int32 or type(step_dict.get(key)[0]) == np.int16 or type==int:\n",
    "            gello_dataset_features[key] = Sequence(Value(\"int64\"),length = len(step_dict.get(key)))\n",
    "        else:\n",
    "            print(\"could not find type for key\")\n",
    "            print(key, type(step_dict.get(key)[0]))\n",
    "    \n",
    "    elif type(step_dict.get(key)) == float:\n",
    "        gello_dataset_features[key] = Value(\"float64\")\n",
    "    \n",
    "    elif type(step_dict.get(key)) == int:\n",
    "        gello_dataset_features[key] = Value(\"int64\")\n",
    "    \n",
    "    else: \n",
    "        print(\"could not find type for key\")\n",
    "        print(key, type(step_dict.get(key)))\n",
    "\n",
    "dataset_features = gello_dataset_features.copy()\n",
    "dataset_features[\"frame_index\"] = Value(\"int64\")\n",
    "dataset_features[\"episode_index\"] = Value(\"int64\")\n",
    "dataset_features[\"index\"] = Value(\"int64\")\n",
    "dataset_features[\"next.done\"] = Value(\"int64\")\n",
    "dataset_features[\"next.success\"] = Value(\"int64\")\n",
    "dataset_features[\"timestep\"] = Value(\"float64\")\n",
    "\n",
    "dataset_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "dataset_dict = {}\n",
    "for key in dataset_features:\n",
    "    dataset_dict[key] = []\n",
    "\n",
    "dataset_idx = 0\n",
    "for episode_idx, episode_path in enumerate(episode_paths):\n",
    "    step_paths = list(episode_path.glob(\"*.pkl\"))\n",
    "    step_paths = sorted(step_paths)\n",
    "    for step_idx, step_path in enumerate(step_paths):\n",
    "        step_dict = pickle.load(open(step_path, \"rb\"))\n",
    "\n",
    "        step_dict[\"frame_index\"] = step_idx\n",
    "        step_dict[\"episode_index\"] = episode_idx\n",
    "        step_dict[\"index\"] = dataset_idx\n",
    "\n",
    "        # assume all demonstrations are successful at the last step. \n",
    "        step_dict[\"next.done\"] = len(step_paths) -1 == step_idx\n",
    "        step_dict[\"next.success\"] = step_dict[\"next.done\"] \n",
    "\n",
    "        step_dict[\"timestep\"] = step_idx * 0.1 # todo: fix hardcoded fps, can parse from filenames.\n",
    "\n",
    "        for key in gello_dataset_features:\n",
    "            if \"rgb\" in key or \"depth\" in key:\n",
    "                # type to uint8 from uint16\n",
    "                step_dict[key] = step_dict[key].astype(np.uint8)\n",
    "                if \"depth\" in key:\n",
    "                    step_dict[key] = step_dict[key][...,0] # (H,W) instead of (1,H,W) for pillow\n",
    "                \n",
    "                step_dict[key] = PILImage.fromarray(step_dict[key])\n",
    "            else:\n",
    "                step_dict[key] = torch.tensor(step_dict.get(key))\n",
    "\n",
    "        for key,value in step_dict.items():\n",
    "            dataset_dict[key].append(value)\n",
    "\n",
    "        dataset_idx += 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint_positions\n",
      "tcp_pose_quat\n",
      "gripper_position\n",
      "wrench\n",
      "control\n"
     ]
    }
   ],
   "source": [
    "for key in dataset_dict:\n",
    "    if type(dataset_dict[key][0]) == torch.Tensor:\n",
    "        print(key)\n",
    "        dataset_dict[key] = torch.stack(dataset_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrist_rgb\n",
      "wrist_depth\n",
      "base_rgb\n",
      "base_depth\n",
      "joint_positions\n",
      "tcp_pose_quat\n",
      "gripper_position\n",
      "wrench\n",
      "control\n",
      "frame_index\n",
      "episode_index\n",
      "index\n",
      "next.done\n",
      "next.success\n",
      "timestep\n"
     ]
    }
   ],
   "source": [
    "hf_dataset = datasets.Dataset.from_dict(dataset_dict, features=Features(dataset_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(hf_dataset[0][\"joint_positions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 9717/9717 [00:09<00:00, 1060.59 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# change control to \"action\"\n",
    "if \"control\" in hf_dataset.column_names:\n",
    "    hf_dataset = hf_dataset.rename_column(\"control\", \"action\")\n",
    "\n",
    "# concatenate two columns into one\n",
    "if not \"observation.state\" in hf_dataset.column_names:  \n",
    "    hf_dataset = hf_dataset.map(lambda x: {\"observation.state\": x[\"joint_positions\"] + x[\"gripper_position\"]})\n",
    "\n",
    "\n",
    "# rename \"wrist_rgb\" to \"observation.image.wrist\" and \"base_rgb\" to \"observation.image.base\"\n",
    "\n",
    "if \"wrist_rgb\" in hf_dataset.column_names:\n",
    "    hf_dataset = hf_dataset.rename_column(\"wrist_rgb\", \"observation.image.wrist\")\n",
    "\n",
    "if \"base_rgb\" in hf_dataset.column_names:\n",
    "    hf_dataset = hf_dataset.rename_column(\"base_rgb\", \"observation.image.base\")\n",
    "\n",
    "# drop wrist_depth and base_depth \n",
    "if \"wrist_depth\" in hf_dataset.column_names:\n",
    "    hf_dataset = hf_dataset.remove_columns(\"wrist_depth\")\n",
    "\n",
    "if \"base_depth\" in hf_dataset.column_names:\n",
    "    hf_dataset = hf_dataset.remove_columns(\"base_depth\")\n",
    "\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.004509274159566701,\n",
       " -1.1877484780601044,\n",
       " 1.68516713777651,\n",
       " -2.0681268177428187,\n",
       " -1.570770565663473,\n",
       " -0.004645172749654591,\n",
       " -0.004645172749654591]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset[0][\"observation.state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hf_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# push the dataset to the hub\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mhf_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mpush_to_hub(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtlpss/planar-push-gello\u001b[39m\u001b[38;5;124m\"\u001b[39m,split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hf_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# push the dataset to the hub\n",
    "hf_dataset.push_to_hub(\"tlpss/planar-push-gello\",split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"tlpss/planar-push-gello\", split=\"train\",revision=\"v1.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change timestamps by dividing by 100\n",
    "dataset = dataset.map(lambda x: {\"timestamp\": x[\"timestamp\"] / 100.0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tcp_pose_quat': [-0.6034055948257446,\n",
       "  -0.12928718328475952,\n",
       "  0.00946362316608429,\n",
       "  -2.2129580974578857,\n",
       "  -2.223250150680542,\n",
       "  -0.004154943395406008],\n",
       " 'wrench': [18.356094360351562,\n",
       "  25.67031478881836,\n",
       "  -34.85917282104492,\n",
       "  -0.6768204569816589,\n",
       "  0.6910861134529114,\n",
       "  -0.015712976455688477],\n",
       " 'frame_index': 1,\n",
       " 'episode_index': 0,\n",
       " 'index': 1,\n",
       " 'timestamp': 0.10000000149011612,\n",
       " 'next.done': False,\n",
       " 'next.success': False,\n",
       " 'observation.state': [-0.009812959469854832,\n",
       "  -1.193248987197876,\n",
       "  1.6807794570922852,\n",
       "  -2.073329448699951,\n",
       "  -1.5757499933242798,\n",
       "  -0.009967454709112644],\n",
       " 'action': [-0.005287617444992065,\n",
       "  -1.1893846988677979,\n",
       "  1.6874358654022217,\n",
       "  -2.068847417831421,\n",
       "  -1.5707963705062866,\n",
       "  -0.005287617444992065],\n",
       " 'observation.images.wrist.rgb': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=640x480>,\n",
       " 'observation.images.base.rgb': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=640x480>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 748/748 [00:00<00:00, 1844.48 examples/s]it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 8/8 [00:00<00:00, 14.51ba/s]\n",
      "Map: 100%|██████████| 748/748 [00:00<00:00, 1559.42 examples/s]8, 17.40s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 8/8 [00:00<00:00, 12.95ba/s]\n",
      "Map: 100%|██████████| 748/748 [00:00<00:00, 1487.23 examples/s]9, 15.43s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 8/8 [00:00<00:00, 14.27ba/s]\n",
      "Map: 100%|██████████| 748/748 [00:00<00:00, 1682.13 examples/s]2, 15.23s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 8/8 [00:00<00:00, 14.03ba/s]\n",
      "Map: 100%|██████████| 748/748 [00:00<00:00, 1397.52 examples/s]8, 15.34s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 8/8 [00:00<00:00, 14.63ba/s]\n",
      "Map: 100%|██████████| 748/748 [00:00<00:00, 1604.32 examples/s]7, 14.63s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 8/8 [00:00<00:00, 14.96ba/s]\n",
      "Map: 100%|██████████| 747/747 [00:00<00:00, 1674.05 examples/s]0, 14.29s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 8/8 [00:00<00:00, 14.46ba/s]\n",
      "Map: 100%|██████████| 747/747 [00:00<00:00, 1617.78 examples/s]3, 13.93s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 8/8 [00:00<00:00, 13.13ba/s]\n",
      "Map: 100%|██████████| 747/747 [00:00<00:00, 1438.13 examples/s]8, 13.77s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 8/8 [00:00<00:00, 13.15ba/s]\n",
      "Map: 100%|██████████| 747/747 [00:00<00:00, 1500.99 examples/s]4, 13.75s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 8/8 [00:00<00:00, 13.50ba/s]\n",
      "Map: 100%|██████████| 747/747 [00:00<00:00, 1549.20 examples/s]40, 13.56s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 8/8 [00:00<00:00, 13.98ba/s]\n",
      "Map: 100%|██████████| 747/747 [00:00<00:00, 1816.22 examples/s]27, 13.60s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 8/8 [00:00<00:00, 13.03ba/s]\n",
      "Map: 100%|██████████| 747/747 [00:00<00:00, 1324.92 examples/s]13, 13.54s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 8/8 [00:00<00:00, 12.46ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 13/13 [03:03<00:00, 14.10s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/tlpss/planar-push-gello/commit/50c767f70013e60162751d97d5b646302af6bd81', commit_message='Upload dataset', commit_description='', oid='50c767f70013e60162751d97d5b646302af6bd81', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload the changes to the hub\n",
    "\n",
    "dataset.push_to_hub(\"tlpss/planar-push-gello\",split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
